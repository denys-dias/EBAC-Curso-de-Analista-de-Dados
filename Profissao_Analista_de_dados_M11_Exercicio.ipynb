{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denys-dias/EBAC-Curso-de-Analista-de-Dados/blob/main/Profissao_Analista_de_dados_M11_Exercicio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ª Parte: Arquivo Robots.txt\n",
        "\n",
        "\n",
        "\n",
        "1.Utilize o pacote Python requests para fazer o download do conteúdo do arquivo robots.txt do site do IMDB e salve numa variável chamada robots , este é o link: https://www.imdb.com/robots.txt\n",
        "\n",
        "2. Com o conteúdo na variável  robots , verifique se a palavra  top  ou  charts está presente no conteúdo do texto. Se sim, imprima  True , senão imprima  False.\n",
        "\n",
        "Dica: Você pode colar o endereço do arquivo robots.txt no seu navegador para visualizar o conteúdo do arquivo."
      ],
      "metadata": {
        "id": "IRMBSeC57_IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "#primeiro eu importo o pacote\n",
        "\n",
        "robots = requests.get(\"https://www.imdb.com/robots.txt\")#Faço o download do arquivo e salvo na variável robots\n",
        "\n",
        "if \"top\" in robots.text or \"charts\" in robots.text:\n",
        "  print(True)\n",
        "else:\n",
        "  print(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1yXf9rr8C_b",
        "outputId": "ff22d289-2653-41d9-9861-83e103fa741a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  2ª Parte: Crawling & Scraping\n",
        "\n",
        "Antes de começar\n",
        "\n",
        "\n",
        "\n",
        "Utilize os pacotes Python  requests  e  beautifulsoup4  para extrair os 10 filmes mais populares do IMDB (titulo, ano e nota), este é o link:\n",
        "https://www.imdb.com/chart/top/\n",
        "\n",
        "\n",
        "\n",
        "Escreva os dados extraídos no arquivo csv  imdb.csv  separado por  ;  no formato indicado no material de apoio.\n",
        " Passo a passo\n",
        "\n",
        "\n",
        "\n",
        "Utilize o pacote requests para fazer o download da página na variável conteúdo\n",
        "Utilize o pacote beautifulsoup4 para carregar o HTML da variável conteúdo na variável pagina\n",
        "Utilize o código indicado no material para iterar nas linhas e nas colunas da tabela e preencha a variável conteudo_extraido\n",
        "Dica: O código já extrai o conteúdo das linhas na lista  textos_coluna, basta que você extraia o conteúdo de interesse dela.\n",
        "\n",
        "\n",
        "\n",
        " Escreva o arquivo imdb.csv com o conteúdo da variável conteudo_extraido"
      ],
      "metadata": {
        "id": "jYhCSH849fAu"
      }
    },
    {
      "source": [
        "import requests\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "from requests.exceptions import HTTPError\n",
        "\n",
        "conteudo = None\n",
        "URL = 'https://www.imdb.com/chart/top/'#link\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
        "    'Accept-Language': 'pt-BR,pt;q=0.9'\n",
        "}#Cabeçalho, padrão\n",
        "\n",
        "try:\n",
        "  resultado = requests.get(url=URL, headers=HEADERS)\n",
        "  resultado.raise_for_status()\n",
        "except HTTPError as exc:\n",
        "  print(exc)\n",
        "else:\n",
        "  conteudo = resultado.text\n",
        "\n",
        "#print(conteudo)\n",
        "\n",
        "pagina = BeautifulSoup(conteudo, 'html.parser')\n",
        "\n",
        "#Extraindo os filmes\n",
        "conteudo_extraido = []\n",
        "\n",
        "movies = pagina.find_all(\"li\", class_=\"ipc-metadata-list-summary-item\") # Eu pego o conteudo da página e atribuo a movies\n",
        "\n",
        "#Através deste for, eu pego somente os 10 primeiros, separo as colunas através do  ; e crio sublista através do método split. Depois atribuo a lista conteudo_extraido\n",
        "for coluna in movies[:10]:\n",
        "    textos_coluna = coluna.get_text(\";\").split(\";\")\n",
        "    textos_coluna = textos_coluna[0].split(\".\") + textos_coluna[1:]\n",
        "    conteudo_extraido.append(textos_coluna)\n",
        "#print(conteudo_extraido)\n",
        "\n",
        "with open(file='imdb.csv', mode='w', encoding='utf-8') as arquivo:\n",
        "  escritor = csv.writer(arquivo, delimiter=',')\n",
        "  escritor.writerow(['ranking', 'titulo', 'ano', 'nota'])\n",
        "  for filme in conteudo_extraido:\n",
        "    ranking = filme[0]\n",
        "    titulo = filme[1]\n",
        "    ano = filme[2]\n",
        "    nota = filme[5]\n",
        "    dados_filme = [ranking, titulo, ano, nota]\n",
        "    escritor.writerow(dados_filme)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4O4onbYRgdp5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}